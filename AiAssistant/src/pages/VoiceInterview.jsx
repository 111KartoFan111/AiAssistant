import React, { useState, useEffect, useRef } from 'react';
import { useParams, useNavigate } from 'react-router-dom';
import { voiceInterviewService } from '../services/voiceInterviewService';
import { Mic, Square } from 'lucide-react';
import './VoiceInterview.css';

function VoiceInterview() {
    const { id } = useParams();
    const navigate = useNavigate();
    
    const [interview, setInterview] = useState(null);
    const [messages, setMessages] = useState([]);
    const [isRecording, setIsRecording] = useState(false);
    const [isProcessing, setIsProcessing] = useState(false);
    const [aiSpeaking, setAiSpeaking] = useState(false);
    const [error, setError] = useState(null);
    
    const mediaRecorderRef = useRef(null);
    const audioChunksRef = useRef([]);
    const audioContextRef = useRef(null);
    const audioElementRef = useRef(null);

    useEffect(() => {
        // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ id —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –≤–∞–ª–∏–¥–µ–Ω
        if (id && id !== 'undefined') {
            loadInterview();
        } else {
            setError('–ù–µ–≤–µ—Ä–Ω—ã–π ID –∏–Ω—Ç–µ—Ä–≤—å—é');
        }
    }, [id]); // –î–æ–±–∞–≤–ª—è–µ–º id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

    const loadInterview = async () => {
        try {
            setError(null);
            const data = await voiceInterviewService.getInterviewDetails(id);
            setInterview(data.interview);
            setMessages(data.messages || []);
        } catch (error) {
            console.error('Failed to load interview:', error);
            setError('–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é');
        }
    };

    const startRecording = async () => {
        try {
            console.log('Starting recording...');
            
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    channelCount: 1,
                    sampleRate: 24000,
                    echoCancellation: true,
                    noiseSuppression: true
                } 
            });
            
            const mimeType = 'audio/webm;codecs=opus';
            
            mediaRecorderRef.current = new MediaRecorder(stream, {
                mimeType: mimeType,
                audioBitsPerSecond: 128000
            });
            
            audioChunksRef.current = [];
            
            mediaRecorderRef.current.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    console.log('Audio chunk received:', event.data.size, 'bytes');
                    audioChunksRef.current.push(event.data);
                }
            };
            
            mediaRecorderRef.current.onstop = async () => {
                console.log('Recording stopped, processing audio...');
                console.log('Total chunks:', audioChunksRef.current.length);
                
                const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
                console.log('Audio blob size:', audioBlob.size, 'bytes');
                
                if (audioBlob.size > 0) {
                    await submitAudio(audioBlob);
                } else {
                    console.error('Audio blob is empty!');
                    alert('–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –∞—É–¥–∏–æ');
                }
                
                stream.getTracks().forEach(track => track.stop());
            };
            
            mediaRecorderRef.current.start(100);
            setIsRecording(true);
            console.log('Recording started successfully');
            
        } catch (error) {
            console.error('Error starting recording:', error);
            alert('–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É: ' + error.message);
        }
    };

    const stopRecording = () => {
        if (mediaRecorderRef.current && isRecording) {
            console.log('Stopping MediaRecorder...');
            mediaRecorderRef.current.stop();
            setIsRecording(false);
        }
    };

    const submitAudio = async (audioBlob) => {
        try {
            setIsProcessing(true);
            console.log('Submitting audio, size:', audioBlob.size);
            
            const response = await voiceInterviewService.submitAudioAnswer(id, audioBlob);
            console.log('Response received:', response);
            
            if (response.success && response.aiResponse) {
                await loadInterview();
                speakText(response.aiResponse);
            }
        } catch (error) {
            console.error('Error submitting audio:', error);
            alert('–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ: ' + error.message);
        } finally {
            setIsProcessing(false);
        }
    };

    const speakText = (text) => {
        if ('speechSynthesis' in window) {
            setAiSpeaking(true);
            
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'ru-RU';
            utterance.rate = 1.0;
            utterance.pitch = 1.0;
            
            utterance.onend = () => {
                setAiSpeaking(false);
            };
            
            utterance.onerror = (error) => {
                console.error('Speech synthesis error:', error);
                setAiSpeaking(false);
            };
            
            window.speechSynthesis.speak(utterance);
        } else {
            console.error('Speech synthesis not supported');
        }
    };

    // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
    if (error) {
        return (
            <div className="voice-interview-container">
                <div className="error-message">
                    <p>{error}</p>
                    <button onClick={() => navigate('/voice-interview-setup')}>
                        –í–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞–∑–∞–¥
                    </button>
                </div>
            </div>
        );
    }

    if (!interview) {
        return (
            <div className="voice-interview-container">
                <div className="loading">–ó–∞–≥—Ä—É–∑–∫–∞...</div>
            </div>
        );
    }

    return (
        <div className="voice-interview-container">
            <div className="interview-header">
                <h2>{interview.positionTitle}</h2>
                <p className="company-name">{interview.companyName}</p>
            </div>

            <div className="messages-container">
                {messages.length === 0 ? (
                    <div className="no-messages">
                        <p>–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é</p>
                    </div>
                ) : (
                    messages.map((message, index) => (
                        <div key={index} className={`message ${message.sender}`}>
                            <div className="message-content">
                                {message.textContent || "üé§ –ê—É–¥–∏–æ —Å–æ–æ–±—â–µ–Ω–∏–µ"}
                            </div>
                        </div>
                    ))
                )}
            </div>

            <div className="interview-controls">
                {aiSpeaking && (
                    <div className="ai-speaking-indicator">
                        AI is speaking...
                    </div>
                )}
                
                {!isRecording ? (
                    <button 
                        className="record-button" 
                        onClick={startRecording}
                        disabled={isProcessing || aiSpeaking}
                    >
                        <Mic size={32} />
                        <span>–ù–∞–∂–º–∏—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω –¥–ª—è –æ—Ç–≤–µ—Ç–∞</span>
                    </button>
                ) : (
                    <button 
                        className="record-button recording" 
                        onClick={stopRecording}
                    >
                        <Square size={32} />
                        <span>–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å</span>
                    </button>
                )}
                
                {isProcessing && (
                    <div className="processing-indicator">
                        –û–±—Ä–∞–±–æ—Ç–∫–∞...
                    </div>
                )}
            </div>
        </div>
    );
}

export default VoiceInterview;